{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riopurba13/keceradasan_buatan_A/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbEtzsONCbXH",
        "outputId": "fac06076-1bef-4faf-f673-c7c7f37a2836"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8kU_wUi2pqB",
        "outputId": "71b09f19-b5bf-473e-ed13-53255f32bb4a"
      },
      "source": [
        "# Download dataset\n",
        "!wget --no-check-certificate \\\n",
        "  github.com/riopurba13/keceradasan_buatan_A/blob/main/Daun_Herbal.zip"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-11-16 14:02:52--  https://github.com/riopurba13/keceradasan_buatan_A/blob/main/Daun_Herbal.zip\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘Daun_Herbal.zip’\n",
            "\n",
            "Daun_Herbal.zip         [ <=>                ] 160.26K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-16 14:02:53 (1.10 MB/s) - ‘Daun_Herbal.zip’ saved [164109]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEbqHHtWCcZi"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'Daun_Herbal.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('Daun_herbal')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTUcSDf2CeBY"
      },
      "source": [
        "base_dir = 'Daun_Herbal'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "\n",
        "\n",
        "train_Daun_Nangka_dir = os.path.join(train_dir, 'Nangka')\n",
        "train_Daun_Belimbing_Wuluh_dir = os.path.join(train_dir, 'Belimbing_Wuluh')\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KUVPIfRCfw0"
      },
      "source": [
        "\n",
        "print(os.listdir(train_Daun_Nangka_dir)[:10])\n",
        "print(os.listdir(train_Daun_Belimbing_Wuluh_dir)[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAsPl9g3Chr2"
      },
      "source": [
        "# Cek jumlah data train dan data validation\n",
        "print('total training Daun Nangka images:', len(os.listdir(train_Daun_Nangka_dir)))\n",
        "print('total training Daun Belimbing Wuluh images:', len(os.listdir(train_Daun_Belimbing_Wuluh_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFVUUI8bCoAv"
      },
      "source": [
        "# Tampilkan 8 image per kelas dengan ukuran 4x4 \n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_cat_pix = [os.path.join(train_Daun_Nangka_dir, fname) \n",
        "                for fname in os.listdir(train_Daun_Nangka_dir)[pic_index-8:pic_index]]\n",
        "next_dog_pix = [os.path.join(Daun_Belimbing_Wuluh_dir, fname) \n",
        "                for fname in os.listdir(Daun_Belimbing_Wuluh_dir)[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_Daun_Nangka_pix+next_Belimbing_Wuluh_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvaNCN1ICqPK"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Gather data train\n",
        "train_data = []\n",
        "train_label = []\n",
        "for r, d, f in os.walk(train_dir):\n",
        "    for file in f:\n",
        "        if \".jpg\" in file:\n",
        "            imagePath = os.path.join(r, file)\n",
        "            image = cv2.imread(imagePath)\n",
        "            image = cv2.resize(image, (150,150))\n",
        "            train_data.append(image)\n",
        "            label = imagePath.split(os.path.sep)[-2]\n",
        "            train_label.append(label)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xytwR-S4Crro"
      },
      "source": [
        "# Gather data validation\n",
        "val_data = []\n",
        "val_label = []\n",
        "for r, d, f in os.walk(validation_dir):\n",
        "    for file in f:\n",
        "        if \".jpg\" in file:\n",
        "            imagePath = os.path.join(r, file)\n",
        "            image = cv2.imread(imagePath)\n",
        "            image = cv2.resize(image, (150,150))\n",
        "            val_data.append(image)\n",
        "            label = imagePath.split(os.path.sep)[-2]\n",
        "            val_label.append(label)\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_label = np.array(val_label)"
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}